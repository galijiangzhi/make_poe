{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8d8a9a72-8677-480c-b3c3-f98706a30c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn.utils.rnn import pad_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dbc15a3f-5507-4de7-b9ad-1774b1f16ed9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5.1+cu121\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "39ccbbdb-ba04-49f7-af41-322a6b15a17c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "文件已成功读取，共 812548 行。\n",
      "文件已成功读取，共 815991 行。\n",
      "文件已成功读取，共 1599430 行。\n"
     ]
    }
   ],
   "source": [
    "text_list = []\n",
    "def read_text_to_list(filepath,lines):\n",
    "    \"\"\"\n",
    "    读取文本文件，将每一行作为一项保存到列表中。\n",
    "\n",
    "    :param filepath: 文本文件路径\n",
    "    :return: 包含文件每一行内容的列表\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # 打开文件，使用 'r' 模式读取，指定编码为 UTF-8\n",
    "        with open(filepath, 'r', encoding='utf-8') as file:\n",
    "            # 逐行读取文件内容\n",
    "            for line in file:\n",
    "                lines.append(line.strip())  # 去掉行末的换行符并添加到列表\n",
    "        print(f\"文件已成功读取，共 {len(lines)} 行。\")\n",
    "    except Exception as e:\n",
    "        print(f\"读取文件时出错：{e}\")\n",
    "\n",
    "read_text_to_list('../../dataset/data_pro/唐诗/七言唐诗.txt',text_list)\n",
    "read_text_to_list('../../dataset/data_pro/唐诗/六言唐诗.txt',text_list)\n",
    "read_text_to_list('../../dataset/data_pro/唐诗/五言唐诗.txt',text_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "494c62e4-b73b-4ee0-847d-8ae5fef51da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_text,target_text = [],[]\n",
    "for i in text_list:\n",
    "    label_text.append(i.split()[0])\n",
    "    target_text.append(i.split()[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a70e21ea-9fb8-4660-a679-e96b4787dd6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['少年力学志须彊',\n",
       " '试问邯郸欹枕客',\n",
       " '脂脸轻匀作艳粧',\n",
       " '夭红不见凌霜操',\n",
       " '纷纷朝市竞秋毫',\n",
       " '不问扬澜与彭浪',\n",
       " '似闻疏雨打篷声',\n",
       " '明日觉来浑不记',\n",
       " '夹屋青松翠霭中',\n",
       " '重来乌石冈头路']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_text[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "44ab29e3-5e1c-4de3-adeb-df036162cba9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['得失由来一梦长',\n",
       " '人间几度熟黄粱',\n",
       " '未应洁白似梅香',\n",
       " '漫向春前取次芳',\n",
       " '江上霜风正怒号',\n",
       " '翩然东下日千艘',\n",
       " '枕上悠扬梦半醒',\n",
       " '隔船相语过前汀',\n",
       " '去年经此亦匆匆',\n",
       " '依旧松声带晓风']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_text[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ab8fd51-819a-4cff-bc1f-460a56cc461e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 假设 label_text 和 target_text 是你的数据\n",
    "label_text = [\"label1\", \"label2\", \"label3\"]\n",
    "target_text = [\"target1\", \"target2\", \"target3\"]\n",
    "\n",
    "# 定义分词器\n",
    "tokenizer = get_tokenizer(\"basic_english\")\n",
    "\n",
    "# 构建词汇表\n",
    "def yield_tokens(data):\n",
    "    for text in data:\n",
    "        yield tokenizer(text)\n",
    "\n",
    "vocab = build_vocab_from_iterator(yield_tokens(label_text + target_text), specials=[\"<unk>\", \"<pad>\"])\n",
    "vocab.set_default_index(vocab[\"<unk>\"])\n",
    "\n",
    "# 将文本转换为索引序列\n",
    "label_sequences = [torch.tensor(vocab(tokenizer(text)), dtype=torch.long) for text in lacbel_text]\n",
    "target_sequences = [torch.tensor(vocab(tokenizer(text)), dtype=torch.long) for text in target_text]\n",
    "\n",
    "# 填充序列，使它们具有相同的长度\n",
    "label_sequences = pad_sequence(label_sequences, batch_first=True, padding_value=vocab[\"<pad>\"])\n",
    "target_sequences = pad_sequence(target_sequences, batch_first=True, padding_value=vocab[\"<pad>\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
